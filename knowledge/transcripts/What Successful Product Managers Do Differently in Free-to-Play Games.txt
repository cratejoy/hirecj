What successful product managers do differently in free-to-play games? Well, this was actually the question that I asked myself some six to seven months ago when I was offered a role as a head of product management at Rovio. And the thing is, even though I had the experience, so I worked as a product manager first at Digital Chocolate, then at Supercell and Rovio, and then in more of a game leadership role as an executive producer at Zynga, and then studio lead at FunPlus. So even though I had the experience of working as a product manager, hiring product managers, and managing product managers, I never really sat down and conceptualized what makes a good, successful product manager. And most importantly, what are those successful product managers doing differently? So, I approached this in the typical core loop. What I mean by that is, in order to really find out what the successful product managers are doing differently, I first talked to my friends, my colleagues, people I know from various amazing companies like Facebook, Zynga, Wargaming, Natural Motion, FunPlus, EA, you name it. And I asked them two questions. Firstly is, what makes a great product manager? And the second question was more detailed, and that was, can you tell me about a situation where a product manager was succeeding, when they did more than you expected? Based on these questions, and based on the multiple answers that I got from my friends and colleagues, I sort of deconstructed the information and conceptualized it into different themes. And with those themes, I got back to my colleagues and friends and got more feedback, again, deconstructed our feedback, and so forth and so forth, until this place. So, as a result, I got five elements that successful product managers do differently in free-to-play games. But before we jump in into those five elements, let's talk about what do product managers actually do. And the first thing that you might think of is, they animate a lot their presentations. And you're absolutely right. But in addition to that, what product managers do is actually a task of both highly creative elements, like defining, designing, and managing key features, discovering and creating growth levers, but also very many analytical tasks, such as building quantitative models, owning and analyzing game metrics, and overall just managing the business performance. But the role is actually even more complicated because it changes not only based on these tasks, but it also changes based on the lifecycle of the product, whether in pre-production, production, soft launch, or live operations, as well as the culture and the organization of the company. So, the way I see it and the way I like to present it is, I would say product managers have two key goals. The first goal is owning the business side of the game. And what I mean by that is, that in the internal battle of CPI versus LTV, the product managers definitely represent the LTV side. And they focus on the metrics of growth, of retention, and monetization. And their design thinking and their overall goal thinking starts with those metrics first, and they make their decision based on that. The second key goal that I feel product managers have is, helping the leadership make decisions. And why I have an image of a hitman is, product managers don't really have the, we don't have the ability always to pull the trigger, but because we do the analysis, because we do the due diligence, and because we do a lot of the designs, we essentially have the power to adjust the aim. And that's why product managers' goal is to support the decision making. All right, let's go to the details. The first thing that I feel successful product managers do differently in free-to-play games is, they use data to find the low-hanging fruits. And what I mean by low-hanging fruit is, something that requires minimum amount of engineering work, minimum amount of work actually from art perhaps, but has a significant impact. Let's start by talking about what isn't a low-hanging fruit. So the normal process of product management or feature updates, it goes through basically this cycle. You start off with the analysis, you end up in a hypothesis or design, then you prioritize that design based on the cost of the work, and based on the impact, the next step is execution of that design, after which it's further analyzed, and then more hypotheses arise. Pretty standard approach. To give a more clear example of this type of approach would be, let's say, league update in Clash of Clans. So as you probably are well aware of this game and have played it before, the way the leagues function and the way the update would have come is, the analysis shows that players were abusing the matchmaking system by dropping their trophies, and that sort of created a double whammy in the sense that those players abusing the matchmaking systems were able to be matched against weaker players, they were able to raid them quite easily and thus get resources and progress faster through the content. On the other hand, the players that were raided by much stronger opponents were feeling a little bit discouraged, and that would probably affect their retention quite significantly. Based on this analysis, that derives both from quantitative metrics as well as qualitative, the hypothesis or the design is made to reward players to stay at certain trophy level, and most importantly, push them to acquire more trophies and thus be matched against even harder opponents. Because this design has a big effect and it solves a big question in the game, it gets prioritized high, it gets executed, and then with further analysis, the numbers are being tuned, the league feature is getting improved and improved with every update. So this is not a low-hanging fruit. This is what you're expected to do. So let's talk about a low-hanging fruit. A game called Dragons of Atlantis. I don't know how many of you are familiar with this, but just to remind you, this was a Kabam game, and it could be described as Game of War minus key social features plus dragons. At the time, it was fairly successful, and the product team in Kabam were having a good time, but the game had some problems. And the key problem was that they were experiencing a churn of players between citadel levels. So the way it worked is, you upgrade your citadel or your city hall, and that unlocks several more upgrades, both for your troops, your research, your buildings, and then you grind through those, and then you can upgrade your citadel level again, and so forth and so forth. The problem was that they didn't have as much levels for those citadels. And because of that, the citadel levels were quite far away from each other, and they were getting further and further away, and players were honestly just turning out. The metrics were going down as they were progressing through the games, and then players just felt it was too big of a grind to go to the next citadel level. Based on the normal approach of analyzing, hypothesizing, prioritizing, and executing, the product team would have come up with a suggestion of doubling the content of the game, implementing that, and so forth and so forth. But that's a very slow approach. So instead, the product team on the game did something much more simple and more effective. They simply doubled the amount of citadel levels without it really touching the amount of level ups there are. So instead of unlocking 10 new things when leveling up to level 6 of citadel, you just unlocked 5, and then on the 7th level, you unlock the rest of the 5. As a result, with this small update, they were able to increase all the metrics from retention to engagement to monetization. Let's go through another example of an easy, low-hanging fruit. And it's a game called Angry Birds Match. And if you haven't played this game, I would describe it as Candy Crush Saga with Angry Birds and Events. And Events is actually the important part of this game. So let's talk about... Yeah, sorry. So Events are an important part of this game. And there's two types of Events. There's the seasonal Events that last for 2 weeks or 3 weeks. They're pretty large, and visually, they're very different. And then there's the small Events that are happening between the bigger seasonal Events. During their latest... not latest, but a couple of Events ago, when they were running the Valentine's Day Event, what they did differently is at the end of the Event, they added a leaderboard. So as the players went all through 70, 60, 80 different levels, instead of finishing the Event, they ended up in a leaderboard. And that leaderboard was active for as long as the game was active. The product manager in this game, Matteo Speri, analyzed the data. And what he noticed is that adding the leaderboard actually significantly increased the engagement because it kept those highly engaged players progressing through all out Events. And instead of them finishing the Event and waiting for the next one to start, they actually stayed in that Event. And that brought a significant increase, not only through engagement, but also through retention and monetization elements. So, based on this finding, as the Event ended, he made a hypothesis. And that was that when running our smaller Events, those who last between 24 to 72 hours, what if we make a little change? And that change was that after you finish the Event, you can finish it again. So you can get double the price, and that's it. It's just a small data tweak. As a result, the KPIs, or the baseline revenue, pretty much increased 20% with a small data change. So, successful product managers are able to look at the data and make quite significant changes without big use from engineering team. But, even though there's small hanging fruits, even though we're always looking for those, that's always not the case. Because sometimes you just can't find them, or sometimes the target is just too far off. And that's when breaking down those bigger goals, that's when working on bigger features, you're supposed to... And the successful ones are able to break it down to smaller targets. So, let me give an example of how not to do it. And this is my personal example. This is an old game. It's a Facebook game called Army Attack from maybe eight years ago. And I was running this as a lead product manager, and I had the goal of increasing the baseline revenue by 20%. And instead of taking the smart approach of really breaking down where the revenue comes from, maybe thinking about adding some core features, increasing the retention, I went with a much straightforward approach, which was this. As a result, yes, the revenue increased, and the leadership was very happy, but not for a very long time. Because what I ended up doing is I just changed player behavior, player purchasing behavior. And it just created more work, and created cycles in our sales, and overall just wasn't very smart. So, let's talk about a smart example of breaking down big goals. A game called Dawn of Titans. I'm sure all of you played it. And those of you who have played it probably know that it's a highly event-driven game. Our PM on this game, her name is Kim Gelderbaum. I'm not anymore a PM on this game, but when she was, she was given a similar goal than I was, and that is increase the revenue, increase the revenue of events by 20%. And her approach was significantly smarter than mine. So, first she looked at the low-hanging fruit. Can we increase the funnel for the event, the DAU of the event by 20%? Because that would, I mean, that would basically do it. And the answer was no. So what Kim started doing is she started looking at the data. And more importantly, she started looking at how the best players in the events are behaving. And she found out that the best of the players were the most engaged, that made the most sessions, they were the most active, they spent the most time in the game, and most importantly, they were very active in chats. Based on that, she tweaked the event structure in a way that the next event was really designed to push players to act as those engaged players. And those highly engaged players were pushed to act just in that way as the, or even becoming more engaged. Next, she built levers in order to push players to act in the way that was designed. And after that, she created a custom dashboard together with data scientist team that would allow her to follow the event structure, the event progress in real lifetime in order for her to pull the triggers at the right time. As a result, Kim was able to hit her target to a tee at the right time, and just overall broke down a big goal into smaller actionable targets and did her due diligence. So, third thing, turning numbers into a story. And as I tried to show in the slide before with the gun, it's basically saying that as a PM, you have a power of affecting the aim, affecting the decision-making. And as a game lead, I mean, this is often what you experience. There's constantly new ideas coming in left and right, and they're just dropping on you. The quest, the raid bosses, everything that you should be doing, and this comes both from external and internal. And, you know, you need to prioritize your roadmap and you need to make the right decisions. And sometimes it feels like the right decisions aren't made in the right time. So the successful PMs are able to turn those numbers, turn those analysis more into a story and sell it through that. As an example, let's get back to Dawn of Titans. Before there were events for Kim to optimize and grow, there were actually no events in the roadmap at all. The two PMs working on this team, Mr. Anil Dasgupta, who's probably in this room, as well as Lawrence Clark, they created a hypothesis that by adding events to the game, they would be able to increase the baseline. They showed the examples from App Annie, like games like Puzzles and Dragons in the East, as well as Grease games in the West, such as Crime City and War of Nations, I believe. They were all increasing their baseline by running very good events constantly. But that wasn't enough to convince the leadership that events should be done. So instead, this happened. It's a pop-up of a sale, but it's actually not just a sale. So what the guys did is they created an event by themselves. They tweaked the gotcha a little bit so that the likelihood of getting a very rare Titan was increased by tenfold, and that event would run for about three days. They added a pop-up to the game, and they added also a message to the Facebook community, just informing players that this kind of event was going on. As a result, they were able to get some numbers for the story, and the numbers were good because the game hit its highest ARPDAUs during that time. And it ended up in the roadmap being prioritized with the events and the game running through the event cadence. Example number two, Clash of Clans and Japan. So sometimes, so why telling a story through the numbers is important? Because sometimes we just don't have enough data. We think that something is really important, and we just don't have enough data to show it. And it's great to have A-B tests. It's great to have sequential tests. It's great to have the analysis, but sometimes you see something else being done by others, and you're trying to pull that data, but it's just not as concrete. And that's when telling a story is important, and that was kind of the case of the launch of Clash of Clans and Japan. So before the game was launched or relaunched in Japan, the KPIs were very good for the audience, but it wasn't localized or culturalized. And the normal approach when you're seeing good KPIs is basically you contact your localization partner. You set up the order for that localization. It comes in, there's a QA, and then goes to the next update, and hopefully it'll increase your number a little bit. But the story of Japan was a little bit different. At that time, Puzzles & Dragons alone was making more money than Clash of Clans in Japan than Clash of Clans, sorry, at that time, the Puzzles & Dragons were making more money in Japan alone than Clash of Clans throughout the world. So that meant that there was a big market. The second part of the story was that successful, like highly successful Western games, such as Farmville and Candy Crush Saga, were not that big of a success in Japan, despite going through the normal localization route, despite doing the marketing, despite kind of doing their due diligence. So the team looked for a way to be big in Japan. A plan was created, and that plan would take actually three to four times longer to implement than to simply pushing out a new localization update. Yet the plan, the story behind it was that it really put the game into a position where it could be successful in the Japanese market, and thus the leadership decided to go through this slow, more riskier route. And as a result, the game was actually, I believe, first Western mobile game that hit top 10 grossing in the Japanese market. Okay, four, leveraging the knowledge of the peers. This is an interesting topic, and it's actually, yeah. Okay, so leveraging knowledge of the peers. There's two elements in the knowledge leveraging. The one is that there's so much information coming both internally and externally that a product manager need to handle at all time. By external information, I mean the information that is coming just through the market change. You're looking at the market, you're looking at what's going on, you're looking at your own category, you're looking at the games, what kind of updates they're doing. And then there's the internal information. As a product manager, you're pretty much expected to know, not expected, you have to know what's going on with your game, you have to know how your cohorts are behaving, you have to know how your updates are influencing them. And that knowledge is constantly increasing as well with all the new A, B tests, with all the new game launches, it's almost impossible to keep the track of that yourself. And that's why leveraging the knowledge of your peers, of others, is important. A good example of a culture of knowledge sharing is Zynga. At Zynga, the knowledge sharing is being run by the team called Central Product Management. And the knowledge sharing is actually divided into three different categories. First is the numbers reviews, and or sort of a general business updates that are done every three to four weeks. During those updates, basically, PMs together with GMs go through their game, kind of update what's going on on the business side, what have been done, how that affected, and what is being done in the future. Then you have a more intimate setting of knowledge sharing, and that is product launches. So during product launches, the product managers actually show what kind of different A, B tests, what kind of different analysis of the new features have been launched, and share that detailed information with their peers. And thirdly, there's the knowledge sharing of competitive insights, where there's a specific team just looking at different type of games that have been launched and deconstructing those games and providing product managers with that information. Now, you might ask what this has to do with a successful product management. I mean, this is just description of a process. True, but it sets up this next example. Angry Birds Evolution, or more specifically, the lead product manager in this game, Dylan Tredere, what he did was really interesting. So as the game launched, as he went through soft launch and launch, there was constantly more and more need of information. People were asking him both internally as well as outside the team as what's going on, what has been learning, what are the A, B tests, and so forth and so forth. So instead of being sort of a reactive knowledge sharer, he set up a meeting every Friday at about 2 p.m. that lasts between five minutes to 35 minutes. This meeting was called Numbers Review, and everybody was pretty much invited to this meeting, and it turned out from kind of like reactive knowledge sharing to proactive knowledge sharing. And instead of him trying to answer those rapid questions, he would have people come in on that specific day. But it didn't just do that, it did something more. So the meeting was really successful, and it was successful in terms of you went there and you actually learned more about the game. And what we decided to do is, he actually pushed it forward, and now it's something that we do company-wide where we have a one Numbers Review meeting where product managers and product leads are invited, and we go quickly, in about one hour, through the key updates as well as key A, B tests and sequential tests and analysis of the different features, and that kind of grew up into a knowledge sharing meeting. So what Dylan essentially did is, he created a knowledge sharing group where that wasn't really before. Another example of knowledge sharing is this blog, The Constructor Fun. I don't know if, actually, do you mind raising your head for a second if you've ever heard about this? Okay, that's crazy. So, okay, yeah, so The Constructor Fun, I started writing to this blog about six years ago, and it was honestly just something that I did in order to improve my own learnings, and it's still something I do just to learn. And throughout the time, there's just more and more games that were launched, more interesting games, and the games got deeper, and it's almost impossible for one person to really cover those. At the same time, there were great people who started writing their own blogs, such as Anil S. Gupta with Both Guns Blazing and Adam Telfer with Mobile Free-to-Play. And instead of, yeah, and it's kind of turned into this weird, I don't know for them, but it turned for me into this weird kind of competition where I was trying to write better deconstruction instead of learning, it's just, it was weird. So what I tried to do with them is I asked them, would you like to learn together? Would you like to work together? And happily, they said yes, and I learned that I didn't know anything. So by surrounding myself with really smart people that I truly respected, it really leveraged the knowledge. And in short, what I'm trying to say is, you might think you know something, but until you surround yourself with people you respect, who are able to criticize, who are smart, you actually don't know shit. And final one is understanding why different people like different games. Quite often, surprisingly often, I've talked to product managers and they weren't that interested about games per se. They were doing this for something that they felt would progress their careers and progress them to become somewhat service managers, e-commerce people or app people. But the most successful ones are the ones who actually like games. And it's not just about liking games because everybody in this room loves games. There's Fortnite players, League of Legends players, Candy Crush Saga players, you name it. But what really separates a successful product manager from others is they're able to get deeper into the games and actually understand why do different people like them, not just playing always Candy Crush Saga or always Fortnite or always League of Legends, and not just outsourcing this question to the qualitative research team, but actually attempting to answer it yourself. That, ladies and gentlemen, concludes my presentation and please open for questions. APPLAUSE Hello. Hey. You mentioned Clash of Clans had a strategy to go to Japan and that they were really successful. I'm really curious to know what was that strategy and the plan. So the strategy, like in details of what the strategy was? Yeah, as detailed as you can be. I'm a bit brief. I'll be very brief and I'll just say that the strategy involved creating a lot of partnerships with local partners in Japan, as well as focusing on culturalisation of the game and getting a stamp of approval so that the Japanese players felt that this game was made by Japanese. OK. I expect somebody to ask the question of what's the difference between designer and product manager? Hi, great talk. I am a data scientist who's working with the PMs oftentimes about how to improve the monetisation and the metrics that we really care about. I was wondering if you can give us any tips about how to communicate with the PMs from a data scientist perspective, and especially when talking about the statistics and numbers. Yeah, for sure. I'll tell you what the data scientist told me, and that was basically the question of why. Like, why are you looking at this specific number? And instead of answering always to what the product managers are asking you, ask them why are they asking that? And then you get to the root of the problem. Hey, great talk. Thank you. Thank you. Quick question. Where do you see the lines being drawn between design, product, and production? OK. So, it all depends on the ownerships. So, let's put it this way. So, if you have to break it down into very clear ownerships, I would say that the product manager would have the ownership of the business side of the game. So, making sure that it's a successful product, per se. It doesn't mean that the product manager is the only person who makes those decisions, but he owns that part. The design owns the part that the players like, love, and just enjoy the game. And the producer owns the fact that the updates are coming on time, that they're not filled with bugs, and that the production is going forward as planned. So, that would be a very high-level divide of those three. All right. Thank you. Thank you. Thank you.